{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import data\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense,ZeroPadding2D, BatchNormalization, Activation, Layer, ReLU, LeakyReLU,Conv2D,AveragePooling2D,UpSampling2D,Reshape,Flatten\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('finDat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(60000).batch(1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSHAPE = 143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1407, 143)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(DSHAPE, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, DSHAPE])\n",
    "generated_image = generator(noise, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "   \n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return 0.5*real_loss + 0.5*fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 125\n",
    "noise_dim = DSHAPE\n",
    "num_examples_to_generate = 100\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 143), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, gen_losses, disc_losses):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_losses = gen_losses.append(gen_loss.numpy())\n",
    "        disc_losses = disc_losses.append(disc_loss.numpy())\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs, gen_losses, disc_losses, gloss, dloss):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch, gen_losses,disc_losses)\n",
    "    print(\"gen_loss =\" + str(gen_losses[-1]))\n",
    "    print(\"disc_loss =\" + str(disc_losses[-1]))\n",
    "    gloss.append(gen_losses[-1])\n",
    "    dloss.append(disc_losses[-1])\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    x = generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  saved = generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "  return saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "gloss = []\n",
    "dloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =0.4603932\n",
      "disc_loss =0.7572322\n",
      "Time for epoch 1 is 0.25175023078918457 sec\n",
      "gen_loss =0.47960985\n",
      "disc_loss =0.7464527\n",
      "Time for epoch 2 is 0.09537220001220703 sec\n",
      "gen_loss =0.4985545\n",
      "disc_loss =0.73916477\n",
      "Time for epoch 3 is 0.08242678642272949 sec\n",
      "gen_loss =0.51702696\n",
      "disc_loss =0.7301507\n",
      "Time for epoch 4 is 0.08409428596496582 sec\n",
      "gen_loss =0.5347676\n",
      "disc_loss =0.7232249\n",
      "Time for epoch 5 is 0.07982897758483887 sec\n",
      "gen_loss =0.55147874\n",
      "disc_loss =0.7148682\n",
      "Time for epoch 6 is 0.08283114433288574 sec\n",
      "gen_loss =0.5672066\n",
      "disc_loss =0.7102392\n",
      "Time for epoch 7 is 0.08327007293701172 sec\n",
      "gen_loss =0.58182186\n",
      "disc_loss =0.70584536\n",
      "Time for epoch 8 is 0.08201408386230469 sec\n",
      "gen_loss =0.5954981\n",
      "disc_loss =0.7017609\n",
      "Time for epoch 9 is 0.08187508583068848 sec\n",
      "gen_loss =0.6082308\n",
      "disc_loss =0.696313\n",
      "Time for epoch 10 is 0.08310985565185547 sec\n",
      "gen_loss =0.6200365\n",
      "disc_loss =0.69234025\n",
      "Time for epoch 11 is 0.0823659896850586 sec\n",
      "gen_loss =0.6310426\n",
      "disc_loss =0.6881592\n",
      "Time for epoch 12 is 0.0816960334777832 sec\n",
      "gen_loss =0.64145994\n",
      "disc_loss =0.68480265\n",
      "Time for epoch 13 is 0.08299803733825684 sec\n",
      "gen_loss =0.65131617\n",
      "disc_loss =0.68061185\n",
      "Time for epoch 14 is 0.08234691619873047 sec\n",
      "gen_loss =0.6607636\n",
      "disc_loss =0.6759974\n",
      "Time for epoch 15 is 0.15996313095092773 sec\n",
      "gen_loss =0.6697009\n",
      "disc_loss =0.6740235\n",
      "Time for epoch 16 is 0.08562088012695312 sec\n",
      "gen_loss =0.67828625\n",
      "disc_loss =0.6709871\n",
      "Time for epoch 17 is 0.08212518692016602 sec\n",
      "gen_loss =0.68666804\n",
      "disc_loss =0.6697886\n",
      "Time for epoch 18 is 0.08687782287597656 sec\n",
      "gen_loss =0.69477487\n",
      "disc_loss =0.66130877\n",
      "Time for epoch 19 is 0.08362698554992676 sec\n",
      "gen_loss =0.7027273\n",
      "disc_loss =0.65963113\n",
      "Time for epoch 20 is 0.08387017250061035 sec\n",
      "gen_loss =0.71045303\n",
      "disc_loss =0.65536064\n",
      "Time for epoch 21 is 0.08965611457824707 sec\n",
      "gen_loss =0.7181016\n",
      "disc_loss =0.65261877\n",
      "Time for epoch 22 is 0.08433103561401367 sec\n",
      "gen_loss =0.72577155\n",
      "disc_loss =0.6474854\n",
      "Time for epoch 23 is 0.0823979377746582 sec\n",
      "gen_loss =0.73338133\n",
      "disc_loss =0.642583\n",
      "Time for epoch 24 is 0.08519291877746582 sec\n",
      "gen_loss =0.7408323\n",
      "disc_loss =0.63707745\n",
      "Time for epoch 25 is 0.08022093772888184 sec\n",
      "gen_loss =0.74811816\n",
      "disc_loss =0.6286661\n",
      "Time for epoch 26 is 0.08121395111083984 sec\n",
      "gen_loss =0.7552527\n",
      "disc_loss =0.6271924\n",
      "Time for epoch 27 is 0.0898277759552002 sec\n",
      "gen_loss =0.7622869\n",
      "disc_loss =0.6226626\n",
      "Time for epoch 28 is 0.08692693710327148 sec\n",
      "gen_loss =0.7694982\n",
      "disc_loss =0.61462224\n",
      "Time for epoch 29 is 0.08620405197143555 sec\n",
      "gen_loss =0.77702594\n",
      "disc_loss =0.606094\n",
      "Time for epoch 30 is 0.16982507705688477 sec\n",
      "gen_loss =0.78512263\n",
      "disc_loss =0.6027143\n",
      "Time for epoch 31 is 0.08662128448486328 sec\n",
      "gen_loss =0.79424155\n",
      "disc_loss =0.5939785\n",
      "Time for epoch 32 is 0.08543682098388672 sec\n",
      "gen_loss =0.8043598\n",
      "disc_loss =0.58902764\n",
      "Time for epoch 33 is 0.08332490921020508 sec\n",
      "gen_loss =0.81547195\n",
      "disc_loss =0.5826154\n",
      "Time for epoch 34 is 0.08340692520141602 sec\n",
      "gen_loss =0.82733846\n",
      "disc_loss =0.56897867\n",
      "Time for epoch 35 is 0.0849161148071289 sec\n",
      "gen_loss =0.8403047\n",
      "disc_loss =0.5623689\n",
      "Time for epoch 36 is 0.08076000213623047 sec\n",
      "gen_loss =0.85391814\n",
      "disc_loss =0.552819\n",
      "Time for epoch 37 is 0.08202004432678223 sec\n",
      "gen_loss =0.8682551\n",
      "disc_loss =0.5474185\n",
      "Time for epoch 38 is 0.08949494361877441 sec\n",
      "gen_loss =0.8829002\n",
      "disc_loss =0.5406945\n",
      "Time for epoch 39 is 0.08299517631530762 sec\n",
      "gen_loss =0.89698493\n",
      "disc_loss =0.5267773\n",
      "Time for epoch 40 is 0.0820467472076416 sec\n",
      "gen_loss =0.91087717\n",
      "disc_loss =0.51859367\n",
      "Time for epoch 41 is 0.08072137832641602 sec\n",
      "gen_loss =0.9251417\n",
      "disc_loss =0.5019884\n",
      "Time for epoch 42 is 0.08262491226196289 sec\n",
      "gen_loss =0.940619\n",
      "disc_loss =0.50168735\n",
      "Time for epoch 43 is 0.08164715766906738 sec\n",
      "gen_loss =0.95739913\n",
      "disc_loss =0.49107638\n",
      "Time for epoch 44 is 0.08469820022583008 sec\n",
      "gen_loss =0.9757062\n",
      "disc_loss =0.47899398\n",
      "Time for epoch 45 is 0.15997576713562012 sec\n",
      "gen_loss =0.99453306\n",
      "disc_loss =0.46443248\n",
      "Time for epoch 46 is 0.0872037410736084 sec\n",
      "gen_loss =1.0155259\n",
      "disc_loss =0.44389337\n",
      "Time for epoch 47 is 0.08903098106384277 sec\n",
      "gen_loss =1.040345\n",
      "disc_loss =0.4461236\n",
      "Time for epoch 48 is 0.08162212371826172 sec\n",
      "gen_loss =1.0660601\n",
      "disc_loss =0.4294321\n",
      "Time for epoch 49 is 0.08718609809875488 sec\n",
      "gen_loss =1.0930417\n",
      "disc_loss =0.42095804\n",
      "Time for epoch 50 is 0.08304691314697266 sec\n",
      "gen_loss =1.1198429\n",
      "disc_loss =0.40660277\n",
      "Time for epoch 51 is 0.08207178115844727 sec\n",
      "gen_loss =1.1479889\n",
      "disc_loss =0.39396334\n",
      "Time for epoch 52 is 0.0827641487121582 sec\n",
      "gen_loss =1.176644\n",
      "disc_loss =0.3920843\n",
      "Time for epoch 53 is 0.08078384399414062 sec\n",
      "gen_loss =1.2024186\n",
      "disc_loss =0.3853071\n",
      "Time for epoch 54 is 0.08147907257080078 sec\n",
      "gen_loss =1.2270796\n",
      "disc_loss =0.3745454\n",
      "Time for epoch 55 is 0.08554911613464355 sec\n",
      "gen_loss =1.2495434\n",
      "disc_loss =0.35723826\n",
      "Time for epoch 56 is 0.08605194091796875 sec\n",
      "gen_loss =1.2783985\n",
      "disc_loss =0.34471256\n",
      "Time for epoch 57 is 0.08257222175598145 sec\n",
      "gen_loss =1.3130524\n",
      "disc_loss =0.34029138\n",
      "Time for epoch 58 is 0.0862727165222168 sec\n",
      "gen_loss =1.3465782\n",
      "disc_loss =0.32515258\n",
      "Time for epoch 59 is 0.0821540355682373 sec\n",
      "gen_loss =1.3824111\n",
      "disc_loss =0.3422212\n",
      "Time for epoch 60 is 0.16052722930908203 sec\n",
      "gen_loss =1.4062617\n",
      "disc_loss =0.3422089\n",
      "Time for epoch 61 is 0.09146690368652344 sec\n",
      "gen_loss =1.4174217\n",
      "disc_loss =0.30565286\n",
      "Time for epoch 62 is 0.08896207809448242 sec\n",
      "gen_loss =1.4400791\n",
      "disc_loss =0.3002063\n",
      "Time for epoch 63 is 0.08616995811462402 sec\n",
      "gen_loss =1.4760958\n",
      "disc_loss =0.2917686\n",
      "Time for epoch 64 is 0.09132599830627441 sec\n",
      "gen_loss =1.5208352\n",
      "disc_loss =0.293747\n",
      "Time for epoch 65 is 0.08211994171142578 sec\n",
      "gen_loss =1.561366\n",
      "disc_loss =0.289643\n",
      "Time for epoch 66 is 0.08747434616088867 sec\n",
      "gen_loss =1.5886016\n",
      "disc_loss =0.28486186\n",
      "Time for epoch 67 is 0.08408284187316895 sec\n",
      "gen_loss =1.598422\n",
      "disc_loss =0.25333953\n",
      "Time for epoch 68 is 0.08189797401428223 sec\n",
      "gen_loss =1.6251979\n",
      "disc_loss =0.25935814\n",
      "Time for epoch 69 is 0.08391404151916504 sec\n",
      "gen_loss =1.663868\n",
      "disc_loss =0.2647165\n",
      "Time for epoch 70 is 0.08210611343383789 sec\n",
      "gen_loss =1.7003294\n",
      "disc_loss =0.2452504\n",
      "Time for epoch 71 is 0.081024169921875 sec\n",
      "gen_loss =1.7408738\n",
      "disc_loss =0.24719355\n",
      "Time for epoch 72 is 0.08315110206604004 sec\n",
      "gen_loss =1.7617291\n",
      "disc_loss =0.23609078\n",
      "Time for epoch 73 is 0.0819859504699707 sec\n",
      "gen_loss =1.797343\n",
      "disc_loss =0.25290084\n",
      "Time for epoch 74 is 0.08214116096496582 sec\n",
      "gen_loss =1.8068557\n",
      "disc_loss =0.23858458\n",
      "Time for epoch 75 is 0.16337800025939941 sec\n",
      "gen_loss =1.8232689\n",
      "disc_loss =0.2188983\n",
      "Time for epoch 76 is 0.0869290828704834 sec\n",
      "gen_loss =1.8784273\n",
      "disc_loss =0.22583455\n",
      "Time for epoch 77 is 0.09119915962219238 sec\n",
      "gen_loss =1.9240283\n",
      "disc_loss =0.2087509\n",
      "Time for epoch 78 is 0.08309006690979004 sec\n",
      "gen_loss =1.9653506\n",
      "disc_loss =0.21670508\n",
      "Time for epoch 79 is 0.08451414108276367 sec\n",
      "gen_loss =1.9800533\n",
      "disc_loss =0.21629475\n",
      "Time for epoch 80 is 0.0836191177368164 sec\n",
      "gen_loss =1.9805712\n",
      "disc_loss =0.21973082\n",
      "Time for epoch 81 is 0.08182597160339355 sec\n",
      "gen_loss =1.9758103\n",
      "disc_loss =0.21367542\n",
      "Time for epoch 82 is 0.08202815055847168 sec\n",
      "gen_loss =2.0164282\n",
      "disc_loss =0.2103711\n",
      "Time for epoch 83 is 0.08324503898620605 sec\n",
      "gen_loss =2.0453205\n",
      "disc_loss =0.18201515\n",
      "Time for epoch 84 is 0.08005595207214355 sec\n",
      "gen_loss =2.1069212\n",
      "disc_loss =0.19011599\n",
      "Time for epoch 85 is 0.08094906806945801 sec\n",
      "gen_loss =2.1471999\n",
      "disc_loss =0.2043328\n",
      "Time for epoch 86 is 0.08395195007324219 sec\n",
      "gen_loss =2.1181912\n",
      "disc_loss =0.18809402\n",
      "Time for epoch 87 is 0.08341407775878906 sec\n",
      "gen_loss =2.0994887\n",
      "disc_loss =0.17177063\n",
      "Time for epoch 88 is 0.08239579200744629 sec\n",
      "gen_loss =2.16204\n",
      "disc_loss =0.18363622\n",
      "Time for epoch 89 is 0.08087563514709473 sec\n",
      "gen_loss =2.2243156\n",
      "disc_loss =0.18081123\n",
      "Time for epoch 90 is 0.16056180000305176 sec\n",
      "gen_loss =2.2311559\n",
      "disc_loss =0.1848962\n",
      "Time for epoch 91 is 0.08845329284667969 sec\n",
      "gen_loss =2.2096696\n",
      "disc_loss =0.17192435\n",
      "Time for epoch 92 is 0.08742213249206543 sec\n",
      "gen_loss =2.2323027\n",
      "disc_loss =0.17865479\n",
      "Time for epoch 93 is 0.08249497413635254 sec\n",
      "gen_loss =2.2776737\n",
      "disc_loss =0.17855835\n",
      "Time for epoch 94 is 0.08702278137207031 sec\n",
      "gen_loss =2.30867\n",
      "disc_loss =0.17089835\n",
      "Time for epoch 95 is 0.08084774017333984 sec\n",
      "gen_loss =2.3264816\n",
      "disc_loss =0.18443638\n",
      "Time for epoch 96 is 0.08279705047607422 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =2.3123574\n",
      "disc_loss =0.15721124\n",
      "Time for epoch 97 is 0.08373785018920898 sec\n",
      "gen_loss =2.3545053\n",
      "disc_loss =0.17371866\n",
      "Time for epoch 98 is 0.0847921371459961 sec\n",
      "gen_loss =2.3769107\n",
      "disc_loss =0.16872662\n",
      "Time for epoch 99 is 0.08501315116882324 sec\n",
      "gen_loss =2.40072\n",
      "disc_loss =0.15601021\n",
      "Time for epoch 100 is 0.08310389518737793 sec\n",
      "gen_loss =2.421494\n",
      "disc_loss =0.15074503\n",
      "Time for epoch 101 is 0.08134198188781738 sec\n",
      "gen_loss =2.4627757\n",
      "disc_loss =0.16116276\n",
      "Time for epoch 102 is 0.08250999450683594 sec\n",
      "gen_loss =2.4731116\n",
      "disc_loss =0.15591973\n",
      "Time for epoch 103 is 0.08353304862976074 sec\n",
      "gen_loss =2.4742482\n",
      "disc_loss =0.16778529\n",
      "Time for epoch 104 is 0.08397626876831055 sec\n",
      "gen_loss =2.4648848\n",
      "disc_loss =0.14196953\n",
      "Time for epoch 105 is 0.36275196075439453 sec\n",
      "gen_loss =2.5779233\n",
      "disc_loss =0.14938913\n",
      "Time for epoch 106 is 0.08863687515258789 sec\n",
      "gen_loss =2.6080146\n",
      "disc_loss =0.1506187\n",
      "Time for epoch 107 is 0.08391118049621582 sec\n",
      "gen_loss =2.5379725\n",
      "disc_loss =0.14929785\n",
      "Time for epoch 108 is 0.08255791664123535 sec\n",
      "gen_loss =2.5623853\n",
      "disc_loss =0.14802808\n",
      "Time for epoch 109 is 0.08034801483154297 sec\n",
      "gen_loss =2.6636562\n",
      "disc_loss =0.14001542\n",
      "Time for epoch 110 is 0.07860803604125977 sec\n",
      "gen_loss =2.7020774\n",
      "disc_loss =0.14058816\n",
      "Time for epoch 111 is 0.08179974555969238 sec\n",
      "gen_loss =2.6871648\n",
      "disc_loss =0.14727265\n",
      "Time for epoch 112 is 0.08144593238830566 sec\n",
      "gen_loss =2.658776\n",
      "disc_loss =0.1606966\n",
      "Time for epoch 113 is 0.08141708374023438 sec\n",
      "gen_loss =2.6763167\n",
      "disc_loss =0.1342096\n",
      "Time for epoch 114 is 0.0816948413848877 sec\n",
      "gen_loss =2.7703304\n",
      "disc_loss =0.1344738\n",
      "Time for epoch 115 is 0.0835261344909668 sec\n",
      "gen_loss =2.8178391\n",
      "disc_loss =0.15670873\n",
      "Time for epoch 116 is 0.08133506774902344 sec\n",
      "gen_loss =2.7051277\n",
      "disc_loss =0.1301509\n",
      "Time for epoch 117 is 0.08078694343566895 sec\n",
      "gen_loss =2.8350065\n",
      "disc_loss =0.17035642\n",
      "Time for epoch 118 is 0.0807957649230957 sec\n",
      "gen_loss =2.7794752\n",
      "disc_loss =0.14739296\n",
      "Time for epoch 119 is 0.08219623565673828 sec\n",
      "gen_loss =2.8134203\n",
      "disc_loss =0.14005382\n",
      "Time for epoch 120 is 0.16285395622253418 sec\n",
      "gen_loss =2.876151\n",
      "disc_loss =0.1468689\n",
      "Time for epoch 121 is 0.08657479286193848 sec\n",
      "gen_loss =2.8798604\n",
      "disc_loss =0.13867635\n",
      "Time for epoch 122 is 0.08719611167907715 sec\n",
      "gen_loss =2.8997018\n",
      "disc_loss =0.15332371\n",
      "Time for epoch 123 is 0.08281493186950684 sec\n",
      "gen_loss =2.860969\n",
      "disc_loss =0.13735828\n",
      "Time for epoch 124 is 0.08130788803100586 sec\n",
      "gen_loss =2.9452875\n",
      "disc_loss =0.14052165\n",
      "Time for epoch 125 is 0.08472394943237305 sec\n"
     ]
    }
   ],
   "source": [
    "final = train(train_dataset,EPOCHS, gen_losses, disc_losses, gloss, dloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.eval of <tf.Tensor: shape=(100, 143), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.0801862 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.01686485, 0.02430469, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.03326439, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)>>"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = generator(tf.random.normal([1000, noise_dim]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.load('columns.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = pd.DataFrame(generated_images, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = generated.to_pickle(\"gen_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(list(range(0,EPOCHS)),gloss)\n",
    "plt.plot(list(range(0,EPOCHS)),dloss)\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['generator loss','discriminator loss'])\n",
    "plt.savefig('Learning_curve GANdnn')\n",
    "plt.show\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "df5fa5efdf1c60a896ccc8bc52bcd2fc69320846d08f7bc80e2522b0c75b6345"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
