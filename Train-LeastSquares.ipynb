{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import data\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense,ZeroPadding2D, BatchNormalization, Activation, Layer, ReLU, LeakyReLU,Conv2D,AveragePooling2D,UpSampling2D,Reshape,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 962\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('finDat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(60000).batch(962)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSHAPE = 143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(DSHAPE, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, DSHAPE])\n",
    "generated_image = generator(noise, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "   \n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = 0.5*tf.math.reduce_mean((real_output)**2) + 0.5*tf.math.reduce_mean(fake_output**2)\n",
    "    return real_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return tf.math.reduce_mean((fake_output)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpointsL2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "noise_dim = DSHAPE\n",
    "num_examples_to_generate = 50\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 143), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, gen_losses, disc_losses):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_losses = gen_losses.append(gen_loss.numpy())\n",
    "        disc_losses = disc_losses.append(disc_loss.numpy())\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss , discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs, gen_losses, disc_losses, gloss, dloss):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch, gen_losses,disc_losses)\n",
    "    print(\"gen_loss =\" + str(gen_losses[-1]))\n",
    "    print(\"disc_loss =\" + str(disc_losses[-1]))\n",
    "    gloss.append(gen_losses[-1])\n",
    "    dloss.append(disc_losses[-1])\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    x = generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  saved = generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "  return saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "gloss = []\n",
    "dloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =0.10736032\n",
      "disc_loss =0.12233751\n",
      "Time for epoch 1 is 0.48154211044311523 sec\n",
      "gen_loss =0.03712591\n",
      "disc_loss =0.066346265\n",
      "Time for epoch 2 is 0.10625791549682617 sec\n",
      "gen_loss =0.011511226\n",
      "disc_loss =0.039168555\n",
      "Time for epoch 3 is 0.09639573097229004 sec\n",
      "gen_loss =0.0032547964\n",
      "disc_loss =0.022727866\n",
      "Time for epoch 4 is 0.09784102439880371 sec\n",
      "gen_loss =0.000724386\n",
      "disc_loss =0.019202895\n",
      "Time for epoch 5 is 0.09609174728393555 sec\n",
      "gen_loss =0.00016477112\n",
      "disc_loss =0.011166222\n",
      "Time for epoch 6 is 0.09731936454772949 sec\n",
      "gen_loss =4.6093846e-05\n",
      "disc_loss =0.0053862287\n",
      "Time for epoch 7 is 0.0948488712310791 sec\n",
      "gen_loss =2.2160555e-05\n",
      "disc_loss =0.008494082\n",
      "Time for epoch 8 is 0.09573030471801758 sec\n",
      "gen_loss =1.1156347e-05\n",
      "disc_loss =0.006986176\n",
      "Time for epoch 9 is 0.0986790657043457 sec\n",
      "gen_loss =5.531006e-06\n",
      "disc_loss =0.00270519\n",
      "Time for epoch 10 is 0.09329509735107422 sec\n",
      "gen_loss =2.1793542e-06\n",
      "disc_loss =0.0030976746\n",
      "Time for epoch 11 is 0.09653401374816895 sec\n",
      "gen_loss =5.093233e-07\n",
      "disc_loss =0.001738738\n",
      "Time for epoch 12 is 0.09826493263244629 sec\n",
      "gen_loss =4.469268e-09\n",
      "disc_loss =0.00060067774\n",
      "Time for epoch 13 is 0.09644007682800293 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0020832173\n",
      "Time for epoch 14 is 0.09554314613342285 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00064169697\n",
      "Time for epoch 15 is 0.1825709342956543 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00089140376\n",
      "Time for epoch 16 is 0.09746527671813965 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0008004993\n",
      "Time for epoch 17 is 0.09675383567810059 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00039743548\n",
      "Time for epoch 18 is 0.09396791458129883 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00077959173\n",
      "Time for epoch 19 is 0.09651994705200195 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0006159491\n",
      "Time for epoch 20 is 0.10164213180541992 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0006631025\n",
      "Time for epoch 21 is 0.09895110130310059 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0003560292\n",
      "Time for epoch 22 is 0.09754300117492676 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00090028526\n",
      "Time for epoch 23 is 0.10049891471862793 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0010993502\n",
      "Time for epoch 24 is 0.1000521183013916 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00055504555\n",
      "Time for epoch 25 is 0.09692072868347168 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0006828821\n",
      "Time for epoch 26 is 0.1088111400604248 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00012645248\n",
      "Time for epoch 27 is 0.10107898712158203 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.1446805e-05\n",
      "Time for epoch 28 is 0.09467315673828125 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00016464095\n",
      "Time for epoch 29 is 0.09914088249206543 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00016065239\n",
      "Time for epoch 30 is 0.17124509811401367 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00025527843\n",
      "Time for epoch 31 is 0.10596990585327148 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0003544227\n",
      "Time for epoch 32 is 0.09858393669128418 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00015158254\n",
      "Time for epoch 33 is 0.0966639518737793 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00077569654\n",
      "Time for epoch 34 is 0.0985422134399414 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0007296176\n",
      "Time for epoch 35 is 0.09482812881469727 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.004993051\n",
      "Time for epoch 36 is 0.0942080020904541 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00017218156\n",
      "Time for epoch 37 is 0.09822797775268555 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0010328498\n",
      "Time for epoch 38 is 0.0959479808807373 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0002696272\n",
      "Time for epoch 39 is 0.09276103973388672 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00038248277\n",
      "Time for epoch 40 is 0.10221624374389648 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.000114926945\n",
      "Time for epoch 41 is 0.09505414962768555 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00015944874\n",
      "Time for epoch 42 is 0.09519004821777344 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00018568989\n",
      "Time for epoch 43 is 0.09596705436706543 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.767182e-05\n",
      "Time for epoch 44 is 0.09801506996154785 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0002724431\n",
      "Time for epoch 45 is 0.17809009552001953 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00023108494\n",
      "Time for epoch 46 is 0.10279297828674316 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0003620807\n",
      "Time for epoch 47 is 0.11958909034729004 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00069735735\n",
      "Time for epoch 48 is 0.09601879119873047 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0015498023\n",
      "Time for epoch 49 is 0.10315918922424316 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.7055756e-05\n",
      "Time for epoch 50 is 0.11375164985656738 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.4622262e-05\n",
      "Time for epoch 51 is 0.10382199287414551 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00011028836\n",
      "Time for epoch 52 is 0.09800291061401367 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00011961911\n",
      "Time for epoch 53 is 0.10959887504577637 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00040147916\n",
      "Time for epoch 54 is 0.1120297908782959 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.096974e-05\n",
      "Time for epoch 55 is 0.1057748794555664 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.6691916e-05\n",
      "Time for epoch 56 is 0.0983271598815918 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00012003654\n",
      "Time for epoch 57 is 0.0973200798034668 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =5.3104566e-05\n",
      "Time for epoch 58 is 0.09598898887634277 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00010787277\n",
      "Time for epoch 59 is 0.09451889991760254 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.000105949715\n",
      "Time for epoch 60 is 0.17131805419921875 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.6119836e-05\n",
      "Time for epoch 61 is 0.1010141372680664 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0002458601\n",
      "Time for epoch 62 is 0.10346293449401855 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.9913574e-05\n",
      "Time for epoch 63 is 0.09782981872558594 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.9756644e-05\n",
      "Time for epoch 64 is 0.09710979461669922 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00023936963\n",
      "Time for epoch 65 is 0.09744095802307129 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.4389264e-05\n",
      "Time for epoch 66 is 0.09968209266662598 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.239826e-05\n",
      "Time for epoch 67 is 0.0969550609588623 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00017728949\n",
      "Time for epoch 68 is 0.09569001197814941 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.776377e-05\n",
      "Time for epoch 69 is 0.09491109848022461 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.0275991e-06\n",
      "Time for epoch 70 is 0.10654211044311523 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.5418874e-05\n",
      "Time for epoch 71 is 0.11112380027770996 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 72 is 0.11222028732299805 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.211505e-05\n",
      "Time for epoch 73 is 0.1059122085571289 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.3451316e-05\n",
      "Time for epoch 74 is 0.09710693359375 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =7.786667e-06\n",
      "Time for epoch 75 is 0.17517328262329102 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.848237e-06\n",
      "Time for epoch 76 is 0.11304497718811035 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.0993095e-05\n",
      "Time for epoch 77 is 0.11308789253234863 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.59222e-05\n",
      "Time for epoch 78 is 0.1017000675201416 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 79 is 0.0987701416015625 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0014082164\n",
      "Time for epoch 80 is 0.09405899047851562 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0002586326\n",
      "Time for epoch 81 is 0.0934441089630127 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.0691372e-06\n",
      "Time for epoch 82 is 0.09763717651367188 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.260521e-05\n",
      "Time for epoch 83 is 0.10503768920898438 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.1222907e-06\n",
      "Time for epoch 84 is 0.1132352352142334 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =7.682675e-06\n",
      "Time for epoch 85 is 0.11522698402404785 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00021315616\n",
      "Time for epoch 86 is 0.11133074760437012 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.0238479e-05\n",
      "Time for epoch 87 is 0.10729694366455078 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00017538191\n",
      "Time for epoch 88 is 0.11060595512390137 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.735402e-05\n",
      "Time for epoch 89 is 0.10785794258117676 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0002276636\n",
      "Time for epoch 90 is 0.17284202575683594 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.9899522e-05\n",
      "Time for epoch 91 is 0.10031414031982422 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00019574122\n",
      "Time for epoch 92 is 0.09841203689575195 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.1389756e-08\n",
      "Time for epoch 93 is 0.09607410430908203 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.47132e-06\n",
      "Time for epoch 94 is 0.0954289436340332 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 95 is 0.09882092475891113 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0026108166\n",
      "Time for epoch 96 is 0.09612083435058594 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.0009904e-06\n",
      "Time for epoch 97 is 0.09588003158569336 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.46066e-06\n",
      "Time for epoch 98 is 0.09595203399658203 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.4290264e-05\n",
      "Time for epoch 99 is 0.09717082977294922 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.2792967e-05\n",
      "Time for epoch 100 is 0.09702515602111816 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =0.0\n",
      "disc_loss =1.5389209e-05\n",
      "Time for epoch 101 is 0.0943453311920166 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.8790499e-07\n",
      "Time for epoch 102 is 0.09557199478149414 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.000105934894\n",
      "Time for epoch 103 is 0.09369015693664551 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =5.645769e-06\n",
      "Time for epoch 104 is 0.09481287002563477 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.154166e-05\n",
      "Time for epoch 105 is 0.18477797508239746 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00013371377\n",
      "Time for epoch 106 is 0.11040997505187988 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.28457e-05\n",
      "Time for epoch 107 is 0.10278606414794922 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.066258e-06\n",
      "Time for epoch 108 is 0.1104729175567627 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00024715028\n",
      "Time for epoch 109 is 0.11578202247619629 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.4146158e-06\n",
      "Time for epoch 110 is 0.11699700355529785 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.5909635e-06\n",
      "Time for epoch 111 is 0.10072088241577148 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.1644116e-05\n",
      "Time for epoch 112 is 0.09630179405212402 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.28387e-05\n",
      "Time for epoch 113 is 0.0973958969116211 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 114 is 0.10110688209533691 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =5.0879953e-07\n",
      "Time for epoch 115 is 0.10892605781555176 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.968506e-07\n",
      "Time for epoch 116 is 0.10543203353881836 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.0260109e-05\n",
      "Time for epoch 117 is 0.09837126731872559 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.914768e-08\n",
      "Time for epoch 118 is 0.10384631156921387 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =5.990833e-06\n",
      "Time for epoch 119 is 0.12482619285583496 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.030326e-05\n",
      "Time for epoch 120 is 0.2060389518737793 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.3176604e-05\n",
      "Time for epoch 121 is 0.118499755859375 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.4735458e-05\n",
      "Time for epoch 122 is 0.10930204391479492 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.7392444e-06\n",
      "Time for epoch 123 is 0.09836602210998535 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.244583e-06\n",
      "Time for epoch 124 is 0.09859704971313477 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.143538e-05\n",
      "Time for epoch 125 is 0.09735918045043945 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 126 is 0.09599995613098145 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00019802581\n",
      "Time for epoch 127 is 0.11410403251647949 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.4150847e-07\n",
      "Time for epoch 128 is 0.11515688896179199 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =7.598696e-08\n",
      "Time for epoch 129 is 0.10844087600708008 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.7609678e-05\n",
      "Time for epoch 130 is 0.10511994361877441 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.223121e-05\n",
      "Time for epoch 131 is 0.1165609359741211 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.9023395e-06\n",
      "Time for epoch 132 is 0.1087958812713623 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00015631784\n",
      "Time for epoch 133 is 0.10423088073730469 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.9391026e-05\n",
      "Time for epoch 134 is 0.11400413513183594 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.186466e-05\n",
      "Time for epoch 135 is 0.18604183197021484 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.0292596e-05\n",
      "Time for epoch 136 is 0.10150003433227539 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 137 is 0.09914398193359375 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00028382125\n",
      "Time for epoch 138 is 0.10078883171081543 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =8.958972e-05\n",
      "Time for epoch 139 is 0.10563302040100098 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.3699684e-07\n",
      "Time for epoch 140 is 0.1059420108795166 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =9.642505e-07\n",
      "Time for epoch 141 is 0.09523391723632812 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 142 is 0.09442615509033203 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.072749e-05\n",
      "Time for epoch 143 is 0.09521007537841797 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.0937643e-05\n",
      "Time for epoch 144 is 0.10318207740783691 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.151603e-06\n",
      "Time for epoch 145 is 0.09787893295288086 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.4648783e-06\n",
      "Time for epoch 146 is 0.10006117820739746 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.6964885e-05\n",
      "Time for epoch 147 is 0.09718203544616699 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00012722737\n",
      "Time for epoch 148 is 0.09916114807128906 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.01368205e-05\n",
      "Time for epoch 149 is 0.10272789001464844 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.000101425045\n",
      "Time for epoch 150 is 0.19637703895568848 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0011200866\n",
      "Time for epoch 151 is 0.12533926963806152 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.182099e-05\n",
      "Time for epoch 152 is 0.11104488372802734 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0012347751\n",
      "Time for epoch 153 is 0.1041879653930664 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 154 is 0.11827492713928223 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =7.994497e-05\n",
      "Time for epoch 155 is 0.11205720901489258 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.9916577e-07\n",
      "Time for epoch 156 is 0.10471296310424805 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 157 is 0.0956120491027832 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.2963785e-06\n",
      "Time for epoch 158 is 0.11790108680725098 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.6656293e-09\n",
      "Time for epoch 159 is 0.11630392074584961 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.6216364e-07\n",
      "Time for epoch 160 is 0.1131739616394043 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00041184382\n",
      "Time for epoch 161 is 0.1117098331451416 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.00010259828\n",
      "Time for epoch 162 is 0.11314678192138672 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 163 is 0.1112971305847168 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 164 is 0.09909415245056152 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.0579057e-05\n",
      "Time for epoch 165 is 0.17289996147155762 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 166 is 0.11789298057556152 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 167 is 0.11701488494873047 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 168 is 0.10590386390686035 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =5.9093145e-06\n",
      "Time for epoch 169 is 0.09907388687133789 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 170 is 0.09698295593261719 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.2038066e-06\n",
      "Time for epoch 171 is 0.0970008373260498 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 172 is 0.09933590888977051 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.0147569e-05\n",
      "Time for epoch 173 is 0.09587311744689941 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.2499963e-06\n",
      "Time for epoch 174 is 0.0932929515838623 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.1831445e-05\n",
      "Time for epoch 175 is 0.09578394889831543 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 176 is 0.09709692001342773 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.0634586e-06\n",
      "Time for epoch 177 is 0.09701919555664062 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.0539055e-08\n",
      "Time for epoch 178 is 0.10083985328674316 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.595194e-06\n",
      "Time for epoch 179 is 0.09830331802368164 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 180 is 0.17913198471069336 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 181 is 0.10366177558898926 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.3764027e-05\n",
      "Time for epoch 182 is 0.10067367553710938 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =6.2216386e-06\n",
      "Time for epoch 183 is 0.09700393676757812 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =3.0544383e-05\n",
      "Time for epoch 184 is 0.0972440242767334 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 185 is 0.10090303421020508 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 186 is 0.10492801666259766 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.2750164e-06\n",
      "Time for epoch 187 is 0.09793996810913086 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =1.24152675e-05\n",
      "Time for epoch 188 is 0.09568428993225098 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 189 is 0.09623503684997559 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =2.169811e-05\n",
      "Time for epoch 190 is 0.09630298614501953 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 191 is 0.0948021411895752 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 192 is 0.09457206726074219 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =4.975856e-06\n",
      "Time for epoch 193 is 0.09538412094116211 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 194 is 0.09487390518188477 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =7.4391032e-06\n",
      "Time for epoch 195 is 0.1706540584564209 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 196 is 0.09699392318725586 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 197 is 0.09674406051635742 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 198 is 0.094696044921875 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 199 is 0.09419584274291992 sec\n",
      "gen_loss =0.0\n",
      "disc_loss =0.0\n",
      "Time for epoch 200 is 0.09527206420898438 sec\n"
     ]
    }
   ],
   "source": [
    "final = train(train_dataset,EPOCHS, gen_losses, disc_losses, gloss, dloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.eval of <tf.Tensor: shape=(50, 143), dtype=float32, numpy=\n",
       "array([[0.        , 0.45634902, 0.4358928 , ..., 0.        , 0.7442949 ,\n",
       "        0.01004054],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.4741718 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.14577867, ..., 0.        , 0.30105567,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.06583896, 0.41397482, 0.42327443, ..., 0.        , 0.44163573,\n",
       "        0.        ],\n",
       "       [0.15938419, 0.2949909 , 0.2957939 , ..., 0.        , 0.5751798 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.39786127, 0.32274055, ..., 0.        , 0.3726675 ,\n",
       "        0.        ]], dtype=float32)>>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.load('columns.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['formula_similarity', 'totreldiff', 'formula_frac',\n",
       "       'num_elements_sc', 'lata_2', 'latb_2', 'latc_2', 'band_gap_2',\n",
       "       'density_2', 'e_above_hull_2', 'efermi_2', 'encut_2', 'energy_2',\n",
       "       'energy_per_atom_2', 'final_energy_2', 'final_energy_per_atom_2',\n",
       "       'formation_energy_per_atom_2', 'nsites_2', 'ntask_ids_2',\n",
       "       'total_magnetization_2', 'cell_volume_2', 'exchange_symmetry_2',\n",
       "       'num_unique_magnetic_sites_2',\n",
       "       'total_magnetization_normalized_vol_2',\n",
       "       'total_magnetization_normalized_formula_units_2',\n",
       "       'num_magnetic_sites_2', 'true_total_magnetization_2',\n",
       "       'Reason for exclusion', 'crystal_temp_2', 'cubic', 'hexagonal',\n",
       "       'monoclinic', 'orthorhombic', 'tetragonal', 'triclinic',\n",
       "       'trigonal', 'primitive', 'base-centered', 'body-centered',\n",
       "       'face-centered', 'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F',\n",
       "       'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca',\n",
       "       'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga',\n",
       "       'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo',\n",
       "       'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I',\n",
       "       'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd',\n",
       "       'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re',\n",
       "       'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn',\n",
       "       'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk',\n",
       "       'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = pd.DataFrame(final, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = generated.to_pickle(\"klgen_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(list(range(0,EPOCHS)),gloss)\n",
    "plt.plot(list(range(0,EPOCHS)),dloss)\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['generator loss','discriminator loss'])\n",
    "plt.savefig('Learning_curve GAN least squares')\n",
    "plt.show\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "df5fa5efdf1c60a896ccc8bc52bcd2fc69320846d08f7bc80e2522b0c75b6345"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
