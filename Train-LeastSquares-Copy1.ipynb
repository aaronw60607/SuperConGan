{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import data\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense,ZeroPadding2D, BatchNormalization, Activation, Layer, ReLU, LeakyReLU,Conv2D,AveragePooling2D,UpSampling2D,Reshape,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 962\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('finDat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(60000).batch(962)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSHAPE = 284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(DSHAPE, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, DSHAPE])\n",
    "generated_image = generator(noise, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "   \n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = 0.5*tf.math.reduce_mean((real_output)**2) + 0.5*tf.math.reduce_mean(fake_output**2)\n",
    "    return real_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return tf.math.reduce_mean((fake_output)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpointsL2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "noise_dim = DSHAPE\n",
    "num_examples_to_generate = 50\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 284), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, gen_losses, disc_losses):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_losses = gen_losses.append(gen_loss.numpy())\n",
    "        disc_losses = disc_losses.append(disc_loss.numpy())\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs, gen_losses, disc_losses, gloss, dloss):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch, gen_losses,disc_losses)\n",
    "    print(\"gen_loss =\" + str(gen_losses[-1]))\n",
    "    print(\"disc_loss =\" + str(disc_losses[-1]))\n",
    "    gloss.append(gen_losses[-1])\n",
    "    dloss.append(disc_losses[-1])\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    x = generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  saved = generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "  return saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "gloss = []\n",
    "dloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =0.060624305\n",
      "disc_loss =0.071061075\n",
      "Time for epoch 1 is 0.34661078453063965 sec\n",
      "gen_loss =0.026564864\n",
      "disc_loss =0.039759662\n",
      "Time for epoch 2 is 0.25810790061950684 sec\n",
      "gen_loss =0.012241357\n",
      "disc_loss =0.021960262\n",
      "Time for epoch 3 is 0.29386305809020996 sec\n",
      "gen_loss =0.0060195937\n",
      "disc_loss =0.01424025\n",
      "Time for epoch 4 is 0.2868809700012207 sec\n",
      "gen_loss =0.0032154853\n",
      "disc_loss =0.008702753\n",
      "Time for epoch 5 is 0.28747105598449707 sec\n",
      "gen_loss =0.0018650821\n",
      "disc_loss =0.006474263\n",
      "Time for epoch 6 is 0.27715301513671875 sec\n",
      "gen_loss =0.0011696984\n",
      "disc_loss =0.004635112\n",
      "Time for epoch 7 is 0.264340877532959 sec\n",
      "gen_loss =0.0007883267\n",
      "disc_loss =0.0039081727\n",
      "Time for epoch 8 is 0.2923448085784912 sec\n",
      "gen_loss =0.0005678054\n",
      "disc_loss =0.002928422\n",
      "Time for epoch 9 is 0.29558587074279785 sec\n",
      "gen_loss =0.00043019326\n",
      "disc_loss =0.0024883032\n",
      "Time for epoch 10 is 0.2567570209503174 sec\n",
      "gen_loss =0.0003389917\n",
      "disc_loss =0.0020479509\n",
      "Time for epoch 11 is 0.2790830135345459 sec\n",
      "gen_loss =0.00027543877\n",
      "disc_loss =0.001837112\n",
      "Time for epoch 12 is 0.2838740348815918 sec\n",
      "gen_loss =0.00022926819\n",
      "disc_loss =0.0017336814\n",
      "Time for epoch 13 is 0.25771093368530273 sec\n",
      "gen_loss =0.00019427382\n",
      "disc_loss =0.0013041191\n",
      "Time for epoch 14 is 0.26244306564331055 sec\n",
      "gen_loss =0.00016683164\n",
      "disc_loss =0.0013306213\n",
      "Time for epoch 15 is 0.33473801612854004 sec\n",
      "gen_loss =0.00014498997\n",
      "disc_loss =0.0011518073\n",
      "Time for epoch 16 is 0.2641260623931885 sec\n",
      "gen_loss =0.00012737299\n",
      "disc_loss =0.0010392244\n",
      "Time for epoch 17 is 0.25951099395751953 sec\n",
      "gen_loss =0.000112903974\n",
      "disc_loss =0.0008470863\n",
      "Time for epoch 18 is 0.25843286514282227 sec\n",
      "gen_loss =0.000100831\n",
      "disc_loss =0.0008779477\n",
      "Time for epoch 19 is 0.25542116165161133 sec\n",
      "gen_loss =9.056791e-05\n",
      "disc_loss =0.00074433774\n",
      "Time for epoch 20 is 0.2618408203125 sec\n",
      "gen_loss =8.180953e-05\n",
      "disc_loss =0.0007162802\n",
      "Time for epoch 21 is 0.2595360279083252 sec\n",
      "gen_loss =7.423121e-05\n",
      "disc_loss =0.00066804007\n",
      "Time for epoch 22 is 0.25777602195739746 sec\n",
      "gen_loss =6.76078e-05\n",
      "disc_loss =0.0006487688\n",
      "Time for epoch 23 is 0.2568671703338623 sec\n",
      "gen_loss =6.181537e-05\n",
      "disc_loss =0.0005848505\n",
      "Time for epoch 24 is 0.25859808921813965 sec\n",
      "gen_loss =5.6741756e-05\n",
      "disc_loss =0.00044306475\n",
      "Time for epoch 25 is 0.2552189826965332 sec\n",
      "gen_loss =5.228037e-05\n",
      "disc_loss =0.00045420628\n",
      "Time for epoch 26 is 0.2582418918609619 sec\n",
      "gen_loss =4.8310805e-05\n",
      "disc_loss =0.00042164326\n",
      "Time for epoch 27 is 0.2549009323120117 sec\n",
      "gen_loss =4.4758424e-05\n",
      "disc_loss =0.00047157644\n",
      "Time for epoch 28 is 0.26665616035461426 sec\n",
      "gen_loss =4.156855e-05\n",
      "disc_loss =0.00044789753\n",
      "Time for epoch 29 is 0.26360011100769043 sec\n",
      "gen_loss =3.8712602e-05\n",
      "disc_loss =0.00038281054\n",
      "Time for epoch 30 is 0.3376011848449707 sec\n",
      "gen_loss =3.6122685e-05\n",
      "disc_loss =0.0003882081\n",
      "Time for epoch 31 is 0.26862311363220215 sec\n",
      "gen_loss =3.377964e-05\n",
      "disc_loss =0.0003450994\n",
      "Time for epoch 32 is 0.25868916511535645 sec\n",
      "gen_loss =3.1654792e-05\n",
      "disc_loss =0.0003304994\n",
      "Time for epoch 33 is 0.25789403915405273 sec\n",
      "gen_loss =2.97284e-05\n",
      "disc_loss =0.00027366812\n",
      "Time for epoch 34 is 0.259490966796875 sec\n",
      "gen_loss =2.7986627e-05\n",
      "disc_loss =0.00026509937\n",
      "Time for epoch 35 is 0.25469017028808594 sec\n",
      "gen_loss =2.6403572e-05\n",
      "disc_loss =0.00025756017\n",
      "Time for epoch 36 is 0.25911498069763184 sec\n",
      "gen_loss =2.494871e-05\n",
      "disc_loss =0.0002718671\n",
      "Time for epoch 37 is 0.27056407928466797 sec\n",
      "gen_loss =2.360759e-05\n",
      "disc_loss =0.00026504224\n",
      "Time for epoch 38 is 0.2596778869628906 sec\n",
      "gen_loss =2.2363422e-05\n",
      "disc_loss =0.00029254\n",
      "Time for epoch 39 is 0.2805771827697754 sec\n",
      "gen_loss =2.119505e-05\n",
      "disc_loss =0.00025197704\n",
      "Time for epoch 40 is 0.268294095993042 sec\n",
      "gen_loss =2.0115796e-05\n",
      "disc_loss =0.00019538548\n",
      "Time for epoch 41 is 0.2652420997619629 sec\n",
      "gen_loss =1.9111816e-05\n",
      "disc_loss =0.00020390257\n",
      "Time for epoch 42 is 0.3012270927429199 sec\n",
      "gen_loss =1.818399e-05\n",
      "disc_loss =0.00019303581\n",
      "Time for epoch 43 is 0.28034400939941406 sec\n",
      "gen_loss =1.7319606e-05\n",
      "disc_loss =0.00021229617\n",
      "Time for epoch 44 is 0.29712510108947754 sec\n",
      "gen_loss =1.6506308e-05\n",
      "disc_loss =0.00018172711\n",
      "Time for epoch 45 is 0.39652013778686523 sec\n",
      "gen_loss =1.575039e-05\n",
      "disc_loss =0.0001637673\n",
      "Time for epoch 46 is 0.2767908573150635 sec\n",
      "gen_loss =1.5036768e-05\n",
      "disc_loss =0.00017254431\n",
      "Time for epoch 47 is 0.29575300216674805 sec\n",
      "gen_loss =1.4376825e-05\n",
      "disc_loss =0.0001716557\n",
      "Time for epoch 48 is 0.2901341915130615 sec\n",
      "gen_loss =1.3756123e-05\n",
      "disc_loss =0.0001833422\n",
      "Time for epoch 49 is 0.28534698486328125 sec\n",
      "gen_loss =1.3176314e-05\n",
      "disc_loss =0.0001439819\n",
      "Time for epoch 50 is 0.26815295219421387 sec\n",
      "gen_loss =1.2640667e-05\n",
      "disc_loss =0.00013706816\n",
      "Time for epoch 51 is 0.2685079574584961 sec\n",
      "gen_loss =1.2132035e-05\n",
      "disc_loss =0.00013673287\n",
      "Time for epoch 52 is 0.2713801860809326 sec\n",
      "gen_loss =1.1646633e-05\n",
      "disc_loss =0.00015231737\n",
      "Time for epoch 53 is 0.2936429977416992 sec\n",
      "gen_loss =1.1178088e-05\n",
      "disc_loss =9.302712e-05\n",
      "Time for epoch 54 is 0.2976830005645752 sec\n",
      "gen_loss =1.07410715e-05\n",
      "disc_loss =0.00012300514\n",
      "Time for epoch 55 is 0.28313493728637695 sec\n",
      "gen_loss =1.0332983e-05\n",
      "disc_loss =0.00011441693\n",
      "Time for epoch 56 is 0.2914407253265381 sec\n",
      "gen_loss =9.958197e-06\n",
      "disc_loss =0.00011401847\n",
      "Time for epoch 57 is 0.28644776344299316 sec\n",
      "gen_loss =9.599722e-06\n",
      "disc_loss =0.00013570143\n",
      "Time for epoch 58 is 0.32773303985595703 sec\n",
      "gen_loss =9.257147e-06\n",
      "disc_loss =0.00010881101\n",
      "Time for epoch 59 is 0.3010220527648926 sec\n",
      "gen_loss =8.933343e-06\n",
      "disc_loss =0.00012665588\n",
      "Time for epoch 60 is 0.39406585693359375 sec\n",
      "gen_loss =8.624659e-06\n",
      "disc_loss =8.7640925e-05\n",
      "Time for epoch 61 is 0.3123762607574463 sec\n",
      "gen_loss =8.334943e-06\n",
      "disc_loss =0.00010515622\n",
      "Time for epoch 62 is 0.31911587715148926 sec\n",
      "gen_loss =8.055677e-06\n",
      "disc_loss =0.000106275584\n",
      "Time for epoch 63 is 0.30194687843322754 sec\n",
      "gen_loss =7.791325e-06\n",
      "disc_loss =8.2040926e-05\n",
      "Time for epoch 64 is 0.3059728145599365 sec\n",
      "gen_loss =7.547619e-06\n",
      "disc_loss =0.0001153685\n",
      "Time for epoch 65 is 0.3256418704986572 sec\n",
      "gen_loss =7.3160613e-06\n",
      "disc_loss =0.00010791793\n",
      "Time for epoch 66 is 0.29067111015319824 sec\n",
      "gen_loss =7.095149e-06\n",
      "disc_loss =7.670196e-05\n",
      "Time for epoch 67 is 0.29256606101989746 sec\n",
      "gen_loss =6.8838594e-06\n",
      "disc_loss =7.9693345e-05\n",
      "Time for epoch 68 is 0.2688407897949219 sec\n",
      "gen_loss =6.6765238e-06\n",
      "disc_loss =9.445792e-05\n",
      "Time for epoch 69 is 0.2639491558074951 sec\n",
      "gen_loss =6.477568e-06\n",
      "disc_loss =8.512934e-05\n",
      "Time for epoch 70 is 0.2566492557525635 sec\n",
      "gen_loss =6.2882364e-06\n",
      "disc_loss =0.000101424164\n",
      "Time for epoch 71 is 0.2521510124206543 sec\n",
      "gen_loss =6.103737e-06\n",
      "disc_loss =7.579845e-05\n",
      "Time for epoch 72 is 0.26265692710876465 sec\n",
      "gen_loss =5.924467e-06\n",
      "disc_loss =5.5769935e-05\n",
      "Time for epoch 73 is 0.25830888748168945 sec\n",
      "gen_loss =5.754924e-06\n",
      "disc_loss =9.084744e-05\n",
      "Time for epoch 74 is 0.2529900074005127 sec\n",
      "gen_loss =5.588943e-06\n",
      "disc_loss =7.758747e-05\n",
      "Time for epoch 75 is 0.3865671157836914 sec\n",
      "gen_loss =5.4311568e-06\n",
      "disc_loss =8.085336e-05\n",
      "Time for epoch 76 is 0.313295841217041 sec\n",
      "gen_loss =5.2780406e-06\n",
      "disc_loss =6.7084395e-05\n",
      "Time for epoch 77 is 0.3191401958465576 sec\n",
      "gen_loss =5.131941e-06\n",
      "disc_loss =7.5700766e-05\n",
      "Time for epoch 78 is 0.2984330654144287 sec\n",
      "gen_loss =4.9884443e-06\n",
      "disc_loss =6.6571156e-05\n",
      "Time for epoch 79 is 0.282958984375 sec\n",
      "gen_loss =4.854618e-06\n",
      "disc_loss =6.591981e-05\n",
      "Time for epoch 80 is 0.2639458179473877 sec\n",
      "gen_loss =4.725681e-06\n",
      "disc_loss =7.563283e-05\n",
      "Time for epoch 81 is 0.2625429630279541 sec\n",
      "gen_loss =4.598419e-06\n",
      "disc_loss =5.5729517e-05\n",
      "Time for epoch 82 is 0.2698490619659424 sec\n",
      "gen_loss =4.477349e-06\n",
      "disc_loss =5.3849275e-05\n",
      "Time for epoch 83 is 0.2865920066833496 sec\n",
      "gen_loss =4.363472e-06\n",
      "disc_loss =5.975951e-05\n",
      "Time for epoch 84 is 0.3042411804199219 sec\n",
      "gen_loss =4.2536776e-06\n",
      "disc_loss =5.4581313e-05\n",
      "Time for epoch 85 is 0.3114340305328369 sec\n",
      "gen_loss =4.149499e-06\n",
      "disc_loss =6.248059e-05\n",
      "Time for epoch 86 is 0.31377577781677246 sec\n",
      "gen_loss =4.0471045e-06\n",
      "disc_loss =4.3418753e-05\n",
      "Time for epoch 87 is 0.28959107398986816 sec\n",
      "gen_loss =3.9510114e-06\n",
      "disc_loss =6.281664e-05\n",
      "Time for epoch 88 is 0.2844400405883789 sec\n",
      "gen_loss =3.8596795e-06\n",
      "disc_loss =5.3176904e-05\n",
      "Time for epoch 89 is 0.28278017044067383 sec\n",
      "gen_loss =3.7701302e-06\n",
      "disc_loss =5.2835516e-05\n",
      "Time for epoch 90 is 0.39482975006103516 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =3.6833812e-06\n",
      "disc_loss =4.3756085e-05\n",
      "Time for epoch 91 is 0.2905540466308594 sec\n",
      "gen_loss =3.6011465e-06\n",
      "disc_loss =5.006539e-05\n",
      "Time for epoch 92 is 0.2612910270690918 sec\n",
      "gen_loss =3.5198946e-06\n",
      "disc_loss =3.3515982e-05\n",
      "Time for epoch 93 is 0.31652402877807617 sec\n",
      "gen_loss =3.4404848e-06\n",
      "disc_loss =3.835274e-05\n",
      "Time for epoch 94 is 0.29595494270324707 sec\n",
      "gen_loss =3.3671115e-06\n",
      "disc_loss =4.232136e-05\n",
      "Time for epoch 95 is 0.30974793434143066 sec\n",
      "gen_loss =3.2978858e-06\n",
      "disc_loss =4.4236516e-05\n",
      "Time for epoch 96 is 0.31353116035461426 sec\n",
      "gen_loss =3.2296496e-06\n",
      "disc_loss =2.6855003e-05\n",
      "Time for epoch 97 is 0.32170796394348145 sec\n",
      "gen_loss =3.1630968e-06\n",
      "disc_loss =6.0110084e-05\n",
      "Time for epoch 98 is 0.28559017181396484 sec\n",
      "gen_loss =3.0966726e-06\n",
      "disc_loss =3.8193728e-05\n",
      "Time for epoch 99 is 0.2631418704986572 sec\n",
      "gen_loss =3.0324927e-06\n",
      "disc_loss =3.0122808e-05\n",
      "Time for epoch 100 is 0.26233792304992676 sec\n",
      "gen_loss =2.9694247e-06\n",
      "disc_loss =3.604828e-05\n",
      "Time for epoch 101 is 0.2571377754211426 sec\n",
      "gen_loss =2.9074745e-06\n",
      "disc_loss =3.2824555e-05\n",
      "Time for epoch 102 is 0.25920724868774414 sec\n",
      "gen_loss =2.8482166e-06\n",
      "disc_loss =3.7408292e-05\n",
      "Time for epoch 103 is 0.2671351432800293 sec\n",
      "gen_loss =2.7910855e-06\n",
      "disc_loss =4.0459912e-05\n",
      "Time for epoch 104 is 0.25980210304260254 sec\n",
      "gen_loss =2.7359172e-06\n",
      "disc_loss =4.5780318e-05\n",
      "Time for epoch 105 is 0.33837008476257324 sec\n",
      "gen_loss =2.6818288e-06\n",
      "disc_loss =3.130279e-05\n",
      "Time for epoch 106 is 0.26389122009277344 sec\n",
      "gen_loss =2.629759e-06\n",
      "disc_loss =3.4428904e-05\n",
      "Time for epoch 107 is 0.2602388858795166 sec\n",
      "gen_loss =2.5785823e-06\n",
      "disc_loss =2.5453986e-05\n",
      "Time for epoch 108 is 0.26712775230407715 sec\n",
      "gen_loss =2.5289692e-06\n",
      "disc_loss =3.182121e-05\n",
      "Time for epoch 109 is 0.2624330520629883 sec\n",
      "gen_loss =2.4811834e-06\n",
      "disc_loss =3.3938202e-05\n",
      "Time for epoch 110 is 0.2588620185852051 sec\n",
      "gen_loss =2.4344663e-06\n",
      "disc_loss =3.6633777e-05\n",
      "Time for epoch 111 is 0.26012206077575684 sec\n",
      "gen_loss =2.3887683e-06\n",
      "disc_loss =3.6740825e-05\n",
      "Time for epoch 112 is 0.2606050968170166 sec\n",
      "gen_loss =2.3441655e-06\n",
      "disc_loss =2.8712771e-05\n",
      "Time for epoch 113 is 0.2594013214111328 sec\n",
      "gen_loss =2.3014643e-06\n",
      "disc_loss =3.066961e-05\n",
      "Time for epoch 114 is 0.26044392585754395 sec\n",
      "gen_loss =2.2593242e-06\n",
      "disc_loss =2.4200543e-05\n",
      "Time for epoch 115 is 0.25630712509155273 sec\n",
      "gen_loss =2.2182535e-06\n",
      "disc_loss =2.7664832e-05\n",
      "Time for epoch 116 is 0.2593259811401367 sec\n",
      "gen_loss =2.1785204e-06\n",
      "disc_loss =2.481091e-05\n",
      "Time for epoch 117 is 0.2586791515350342 sec\n",
      "gen_loss =2.139352e-06\n",
      "disc_loss =2.070361e-05\n",
      "Time for epoch 118 is 0.26183009147644043 sec\n",
      "gen_loss =2.100943e-06\n",
      "disc_loss =3.2451768e-05\n",
      "Time for epoch 119 is 0.26430606842041016 sec\n",
      "gen_loss =2.0631317e-06\n",
      "disc_loss =2.0329806e-05\n",
      "Time for epoch 120 is 0.3388099670410156 sec\n",
      "gen_loss =2.026244e-06\n",
      "disc_loss =3.275892e-05\n",
      "Time for epoch 121 is 0.27266716957092285 sec\n",
      "gen_loss =1.990432e-06\n",
      "disc_loss =2.4097486e-05\n",
      "Time for epoch 122 is 0.2588999271392822 sec\n",
      "gen_loss =1.9569866e-06\n",
      "disc_loss =3.1323223e-05\n",
      "Time for epoch 123 is 0.26432013511657715 sec\n",
      "gen_loss =1.92449e-06\n",
      "disc_loss =3.1526066e-05\n",
      "Time for epoch 124 is 0.26491498947143555 sec\n",
      "gen_loss =1.8913131e-06\n",
      "disc_loss =3.0391164e-05\n",
      "Time for epoch 125 is 0.2583599090576172 sec\n",
      "gen_loss =1.8588725e-06\n",
      "disc_loss =2.6189487e-05\n",
      "Time for epoch 126 is 0.2581300735473633 sec\n",
      "gen_loss =1.8277029e-06\n",
      "disc_loss =2.6959668e-05\n",
      "Time for epoch 127 is 0.25786399841308594 sec\n",
      "gen_loss =1.7970666e-06\n",
      "disc_loss =2.7797825e-05\n",
      "Time for epoch 128 is 0.258516788482666 sec\n",
      "gen_loss =1.7675338e-06\n",
      "disc_loss =2.6303163e-05\n",
      "Time for epoch 129 is 0.2623171806335449 sec\n",
      "gen_loss =1.7385549e-06\n",
      "disc_loss =2.414002e-05\n",
      "Time for epoch 130 is 0.2644197940826416 sec\n",
      "gen_loss =1.7092212e-06\n",
      "disc_loss =3.0072712e-05\n",
      "Time for epoch 131 is 0.2532649040222168 sec\n",
      "gen_loss =1.6804995e-06\n",
      "disc_loss =3.453272e-05\n",
      "Time for epoch 132 is 0.30916619300842285 sec\n",
      "gen_loss =1.6530116e-06\n",
      "disc_loss =1.8431647e-05\n",
      "Time for epoch 133 is 0.29795098304748535 sec\n",
      "gen_loss =1.6268415e-06\n",
      "disc_loss =2.1471931e-05\n",
      "Time for epoch 134 is 0.31311511993408203 sec\n",
      "gen_loss =1.6014253e-06\n",
      "disc_loss =2.593182e-05\n",
      "Time for epoch 135 is 0.39063596725463867 sec\n",
      "gen_loss =1.576477e-06\n",
      "disc_loss =1.8321027e-05\n",
      "Time for epoch 136 is 0.2884519100189209 sec\n",
      "gen_loss =1.5525433e-06\n",
      "disc_loss =3.8692735e-05\n",
      "Time for epoch 137 is 0.2681698799133301 sec\n",
      "gen_loss =1.5277858e-06\n",
      "disc_loss =2.3507791e-05\n",
      "Time for epoch 138 is 0.2705371379852295 sec\n",
      "gen_loss =1.5037997e-06\n",
      "disc_loss =1.9854153e-05\n",
      "Time for epoch 139 is 0.26500606536865234 sec\n",
      "gen_loss =1.4809176e-06\n",
      "disc_loss =1.5182391e-05\n",
      "Time for epoch 140 is 0.278472900390625 sec\n",
      "gen_loss =1.4586939e-06\n",
      "disc_loss =2.3270111e-05\n",
      "Time for epoch 141 is 0.2589292526245117 sec\n",
      "gen_loss =1.4359682e-06\n",
      "disc_loss =1.7928347e-05\n",
      "Time for epoch 142 is 0.26154184341430664 sec\n",
      "gen_loss =1.4141407e-06\n",
      "disc_loss =1.3489181e-05\n",
      "Time for epoch 143 is 0.27483701705932617 sec\n",
      "gen_loss =1.3936245e-06\n",
      "disc_loss =1.9576566e-05\n",
      "Time for epoch 144 is 0.2660529613494873 sec\n",
      "gen_loss =1.3733799e-06\n",
      "disc_loss =1.8674331e-05\n",
      "Time for epoch 145 is 0.2572188377380371 sec\n",
      "gen_loss =1.3530131e-06\n",
      "disc_loss =1.8270337e-05\n",
      "Time for epoch 146 is 0.26221680641174316 sec\n",
      "gen_loss =1.3335286e-06\n",
      "disc_loss =1.4294722e-05\n",
      "Time for epoch 147 is 0.2641732692718506 sec\n",
      "gen_loss =1.3146657e-06\n",
      "disc_loss =1.3281317e-05\n",
      "Time for epoch 148 is 0.2633490562438965 sec\n",
      "gen_loss =1.295837e-06\n",
      "disc_loss =2.2386868e-05\n",
      "Time for epoch 149 is 0.2648770809173584 sec\n",
      "gen_loss =1.2771781e-06\n",
      "disc_loss =2.2535698e-05\n",
      "Time for epoch 150 is 0.337918758392334 sec\n",
      "gen_loss =1.258545e-06\n",
      "disc_loss =1.66521e-05\n",
      "Time for epoch 151 is 0.2722618579864502 sec\n",
      "gen_loss =1.2398251e-06\n",
      "disc_loss =2.406959e-05\n",
      "Time for epoch 152 is 0.2620210647583008 sec\n",
      "gen_loss =1.2216506e-06\n",
      "disc_loss =1.7669674e-05\n",
      "Time for epoch 153 is 0.25947999954223633 sec\n",
      "gen_loss =1.2036701e-06\n",
      "disc_loss =2.3199349e-05\n",
      "Time for epoch 154 is 0.26903796195983887 sec\n",
      "gen_loss =1.1860185e-06\n",
      "disc_loss =1.9444227e-05\n",
      "Time for epoch 155 is 0.2585129737854004 sec\n",
      "gen_loss =1.1691548e-06\n",
      "disc_loss =1.3755637e-05\n",
      "Time for epoch 156 is 0.26299500465393066 sec\n",
      "gen_loss =1.1530527e-06\n",
      "disc_loss =1.1866973e-05\n",
      "Time for epoch 157 is 0.26334095001220703 sec\n",
      "gen_loss =1.1374196e-06\n",
      "disc_loss =2.1906873e-05\n",
      "Time for epoch 158 is 0.26419496536254883 sec\n",
      "gen_loss =1.1220072e-06\n",
      "disc_loss =1.5647956e-05\n",
      "Time for epoch 159 is 0.259814977645874 sec\n",
      "gen_loss =1.1066014e-06\n",
      "disc_loss =1.3506466e-05\n",
      "Time for epoch 160 is 0.2603018283843994 sec\n",
      "gen_loss =1.0910279e-06\n",
      "disc_loss =1.5893245e-05\n",
      "Time for epoch 161 is 0.2583160400390625 sec\n",
      "gen_loss =1.0763456e-06\n",
      "disc_loss =1.7674245e-05\n",
      "Time for epoch 162 is 0.26604700088500977 sec\n",
      "gen_loss =1.0619602e-06\n",
      "disc_loss =1.35378195e-05\n",
      "Time for epoch 163 is 0.26222801208496094 sec\n",
      "gen_loss =1.0478025e-06\n",
      "disc_loss =1.4637495e-05\n",
      "Time for epoch 164 is 0.2630910873413086 sec\n",
      "gen_loss =1.0339936e-06\n",
      "disc_loss =1.0890151e-05\n",
      "Time for epoch 165 is 0.3395991325378418 sec\n",
      "gen_loss =1.0207825e-06\n",
      "disc_loss =1.3934674e-05\n",
      "Time for epoch 166 is 0.26866698265075684 sec\n",
      "gen_loss =1.0082085e-06\n",
      "disc_loss =6.982933e-06\n",
      "Time for epoch 167 is 0.25957202911376953 sec\n",
      "gen_loss =9.962705e-07\n",
      "disc_loss =2.2806582e-05\n",
      "Time for epoch 168 is 0.26611900329589844 sec\n",
      "gen_loss =9.839868e-07\n",
      "disc_loss =1.3230761e-05\n",
      "Time for epoch 169 is 0.27191901206970215 sec\n",
      "gen_loss =9.715881e-07\n",
      "disc_loss =9.659544e-06\n",
      "Time for epoch 170 is 0.2649271488189697 sec\n",
      "gen_loss =9.591555e-07\n",
      "disc_loss =1.3154392e-05\n",
      "Time for epoch 171 is 0.2631828784942627 sec\n",
      "gen_loss =9.472099e-07\n",
      "disc_loss =1.4023845e-05\n",
      "Time for epoch 172 is 0.26351189613342285 sec\n",
      "gen_loss =9.3535414e-07\n",
      "disc_loss =1.3135042e-05\n",
      "Time for epoch 173 is 0.26107096672058105 sec\n",
      "gen_loss =9.233278e-07\n",
      "disc_loss =1.4094574e-05\n",
      "Time for epoch 174 is 0.2583310604095459 sec\n",
      "gen_loss =9.117216e-07\n",
      "disc_loss =1.5266383e-05\n",
      "Time for epoch 175 is 0.26486825942993164 sec\n",
      "gen_loss =9.002312e-07\n",
      "disc_loss =1.4448639e-05\n",
      "Time for epoch 176 is 0.26236796379089355 sec\n",
      "gen_loss =8.889564e-07\n",
      "disc_loss =1.2015834e-05\n",
      "Time for epoch 177 is 0.2648282051086426 sec\n",
      "gen_loss =8.781675e-07\n",
      "disc_loss =1.05337585e-05\n",
      "Time for epoch 178 is 0.2612290382385254 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =8.6808114e-07\n",
      "disc_loss =1.666309e-05\n",
      "Time for epoch 179 is 0.2709071636199951 sec\n",
      "gen_loss =8.578456e-07\n",
      "disc_loss =1.2999809e-05\n",
      "Time for epoch 180 is 0.34367799758911133 sec\n",
      "gen_loss =8.476975e-07\n",
      "disc_loss =1.9473124e-05\n",
      "Time for epoch 181 is 0.27929234504699707 sec\n",
      "gen_loss =8.3715275e-07\n",
      "disc_loss =9.540394e-06\n",
      "Time for epoch 182 is 0.26207590103149414 sec\n",
      "gen_loss =8.273636e-07\n",
      "disc_loss =1.6374857e-05\n",
      "Time for epoch 183 is 0.2610440254211426 sec\n",
      "gen_loss =8.1731457e-07\n",
      "disc_loss =1.3931424e-05\n",
      "Time for epoch 184 is 0.26208019256591797 sec\n",
      "gen_loss =8.074557e-07\n",
      "disc_loss =1.1312338e-05\n",
      "Time for epoch 185 is 0.26386094093322754 sec\n",
      "gen_loss =7.9768137e-07\n",
      "disc_loss =1.1424041e-05\n",
      "Time for epoch 186 is 0.2575092315673828 sec\n",
      "gen_loss =7.8830504e-07\n",
      "disc_loss =1.9393648e-05\n",
      "Time for epoch 187 is 0.2724730968475342 sec\n",
      "gen_loss =7.787814e-07\n",
      "disc_loss =9.431491e-06\n",
      "Time for epoch 188 is 0.3042411804199219 sec\n",
      "gen_loss =7.696315e-07\n",
      "disc_loss =1.2417861e-05\n",
      "Time for epoch 189 is 0.31128478050231934 sec\n",
      "gen_loss =7.6047536e-07\n",
      "disc_loss =1.0287706e-05\n",
      "Time for epoch 190 is 0.30547094345092773 sec\n",
      "gen_loss =7.5164314e-07\n",
      "disc_loss =1.6143023e-05\n",
      "Time for epoch 191 is 0.3208470344543457 sec\n",
      "gen_loss =7.4310776e-07\n",
      "disc_loss =1.623794e-05\n",
      "Time for epoch 192 is 0.2990288734436035 sec\n",
      "gen_loss =7.34814e-07\n",
      "disc_loss =1.1064707e-05\n",
      "Time for epoch 193 is 0.2673029899597168 sec\n",
      "gen_loss =7.2668564e-07\n",
      "disc_loss =7.723841e-06\n",
      "Time for epoch 194 is 0.26079630851745605 sec\n",
      "gen_loss =7.1885347e-07\n",
      "disc_loss =1.2442373e-05\n",
      "Time for epoch 195 is 0.33837199211120605 sec\n",
      "gen_loss =7.109294e-07\n",
      "disc_loss =1.1548915e-05\n",
      "Time for epoch 196 is 0.2710282802581787 sec\n",
      "gen_loss =7.030245e-07\n",
      "disc_loss =9.21046e-06\n",
      "Time for epoch 197 is 0.2702789306640625 sec\n",
      "gen_loss =6.9539556e-07\n",
      "disc_loss =1.90002e-05\n",
      "Time for epoch 198 is 0.27701783180236816 sec\n",
      "gen_loss =6.8739956e-07\n",
      "disc_loss =7.262895e-06\n",
      "Time for epoch 199 is 0.273712158203125 sec\n",
      "gen_loss =6.794742e-07\n",
      "disc_loss =1.2174374e-05\n",
      "Time for epoch 200 is 0.2777738571166992 sec\n"
     ]
    }
   ],
   "source": [
    "final = train(train_dataset,EPOCHS, gen_losses, disc_losses, gloss, dloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.eval of <tf.Tensor: shape=(50, 284), dtype=float32, numpy=\n",
       "array([[0.07925244, 0.        , 0.3401261 , ..., 0.        , 0.        ,\n",
       "        0.11596388],\n",
       "       [0.21729568, 0.10847286, 0.        , ..., 0.        , 0.        ,\n",
       "        0.37117183],\n",
       "       [0.7245279 , 0.        , 0.28576404, ..., 0.        , 0.        ,\n",
       "        0.7793383 ],\n",
       "       ...,\n",
       "       [0.2528721 , 0.18030162, 0.02239932, ..., 0.        , 0.27466744,\n",
       "        0.5849763 ],\n",
       "       [0.29583615, 0.        , 0.38475183, ..., 0.        , 0.        ,\n",
       "        0.30047476],\n",
       "       [0.24639826, 0.03883468, 0.10360632, ..., 0.        , 0.0037256 ,\n",
       "        0.2618022 ]], dtype=float32)>>"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.load('columns.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['formula_similarity', 'totreldiff', 'formula_frac',\n",
       "       'correct_formula_frac', 'tc', 'sc_class_unique_sc',\n",
       "       'num_elements_sc', 'lata_2', 'latb_2', 'latc_2', 'band_gap_2',\n",
       "       'density_2', 'e_above_hull_2', 'efermi_2', 'encut_2', 'energy_2',\n",
       "       'energy_per_atom_2', 'final_energy_2', 'final_energy_per_atom_2',\n",
       "       'formation_energy_per_atom_2', 'has_bandstructure_2',\n",
       "       'is_ordered_2', 'nsites_2', 'ntask_ids_2', 'total_magnetization_2',\n",
       "       'cell_volume_2', 'is_magnetic_2', 'exchange_symmetry_2',\n",
       "       'num_unique_magnetic_sites_2',\n",
       "       'total_magnetization_normalized_vol_2',\n",
       "       'total_magnetization_normalized_formula_units_2',\n",
       "       'num_magnetic_sites_2', 'true_total_magnetization_2',\n",
       "       'synth_doped', 'crystal_temp_2', 'no_crystal_temp_given_2',\n",
       "       'cubic', 'hexagonal', 'monoclinic', 'orthorhombic', 'tetragonal',\n",
       "       'triclinic', 'trigonal', 'primitive', 'base-centered',\n",
       "       'body-centered', 'face-centered', 'weight', 'Unnamed: 0',\n",
       "       'MagpieData minimum Number', 'MagpieData maximum Number',\n",
       "       'MagpieData range Number', 'MagpieData mean Number',\n",
       "       'MagpieData avg_dev Number', 'MagpieData mode Number',\n",
       "       'MagpieData minimum MendeleevNumber',\n",
       "       'MagpieData maximum MendeleevNumber',\n",
       "       'MagpieData range MendeleevNumber',\n",
       "       'MagpieData mean MendeleevNumber',\n",
       "       'MagpieData avg_dev MendeleevNumber',\n",
       "       'MagpieData mode MendeleevNumber',\n",
       "       'MagpieData minimum AtomicWeight',\n",
       "       'MagpieData maximum AtomicWeight', 'MagpieData range AtomicWeight',\n",
       "       'MagpieData mean AtomicWeight', 'MagpieData avg_dev AtomicWeight',\n",
       "       'MagpieData mode AtomicWeight', 'MagpieData minimum MeltingT',\n",
       "       'MagpieData maximum MeltingT', 'MagpieData range MeltingT',\n",
       "       'MagpieData mean MeltingT', 'MagpieData avg_dev MeltingT',\n",
       "       'MagpieData mode MeltingT', 'MagpieData minimum Column',\n",
       "       'MagpieData maximum Column', 'MagpieData range Column',\n",
       "       'MagpieData mean Column', 'MagpieData avg_dev Column',\n",
       "       'MagpieData mode Column', 'MagpieData minimum Row',\n",
       "       'MagpieData maximum Row', 'MagpieData range Row',\n",
       "       'MagpieData mean Row', 'MagpieData avg_dev Row',\n",
       "       'MagpieData mode Row', 'MagpieData minimum CovalentRadius',\n",
       "       'MagpieData maximum CovalentRadius',\n",
       "       'MagpieData range CovalentRadius',\n",
       "       'MagpieData mean CovalentRadius',\n",
       "       'MagpieData avg_dev CovalentRadius',\n",
       "       'MagpieData mode CovalentRadius',\n",
       "       'MagpieData minimum Electronegativity',\n",
       "       'MagpieData maximum Electronegativity',\n",
       "       'MagpieData range Electronegativity',\n",
       "       'MagpieData mean Electronegativity',\n",
       "       'MagpieData avg_dev Electronegativity',\n",
       "       'MagpieData mode Electronegativity',\n",
       "       'MagpieData minimum NsValence', 'MagpieData maximum NsValence',\n",
       "       'MagpieData range NsValence', 'MagpieData mean NsValence',\n",
       "       'MagpieData avg_dev NsValence', 'MagpieData mode NsValence',\n",
       "       'MagpieData minimum NpValence', 'MagpieData maximum NpValence',\n",
       "       'MagpieData range NpValence', 'MagpieData mean NpValence',\n",
       "       'MagpieData avg_dev NpValence', 'MagpieData mode NpValence',\n",
       "       'MagpieData minimum NdValence', 'MagpieData maximum NdValence',\n",
       "       'MagpieData range NdValence', 'MagpieData mean NdValence',\n",
       "       'MagpieData avg_dev NdValence', 'MagpieData mode NdValence',\n",
       "       'MagpieData minimum NfValence', 'MagpieData maximum NfValence',\n",
       "       'MagpieData range NfValence', 'MagpieData mean NfValence',\n",
       "       'MagpieData avg_dev NfValence', 'MagpieData mode NfValence',\n",
       "       'MagpieData minimum NValence', 'MagpieData maximum NValence',\n",
       "       'MagpieData range NValence', 'MagpieData mean NValence',\n",
       "       'MagpieData avg_dev NValence', 'MagpieData mode NValence',\n",
       "       'MagpieData minimum NsUnfilled', 'MagpieData maximum NsUnfilled',\n",
       "       'MagpieData range NsUnfilled', 'MagpieData mean NsUnfilled',\n",
       "       'MagpieData avg_dev NsUnfilled', 'MagpieData mode NsUnfilled',\n",
       "       'MagpieData minimum NpUnfilled', 'MagpieData maximum NpUnfilled',\n",
       "       'MagpieData range NpUnfilled', 'MagpieData mean NpUnfilled',\n",
       "       'MagpieData avg_dev NpUnfilled', 'MagpieData mode NpUnfilled',\n",
       "       'MagpieData minimum NdUnfilled', 'MagpieData maximum NdUnfilled',\n",
       "       'MagpieData range NdUnfilled', 'MagpieData mean NdUnfilled',\n",
       "       'MagpieData avg_dev NdUnfilled', 'MagpieData mode NdUnfilled',\n",
       "       'MagpieData minimum NfUnfilled', 'MagpieData maximum NfUnfilled',\n",
       "       'MagpieData range NfUnfilled', 'MagpieData mean NfUnfilled',\n",
       "       'MagpieData avg_dev NfUnfilled', 'MagpieData mode NfUnfilled',\n",
       "       'MagpieData minimum NUnfilled', 'MagpieData maximum NUnfilled',\n",
       "       'MagpieData range NUnfilled', 'MagpieData mean NUnfilled',\n",
       "       'MagpieData avg_dev NUnfilled', 'MagpieData mode NUnfilled',\n",
       "       'MagpieData minimum GSvolume_pa', 'MagpieData maximum GSvolume_pa',\n",
       "       'MagpieData range GSvolume_pa', 'MagpieData mean GSvolume_pa',\n",
       "       'MagpieData avg_dev GSvolume_pa', 'MagpieData mode GSvolume_pa',\n",
       "       'MagpieData minimum GSbandgap', 'MagpieData maximum GSbandgap',\n",
       "       'MagpieData range GSbandgap', 'MagpieData mean GSbandgap',\n",
       "       'MagpieData avg_dev GSbandgap', 'MagpieData mode GSbandgap',\n",
       "       'MagpieData minimum GSmagmom', 'MagpieData maximum GSmagmom',\n",
       "       'MagpieData range GSmagmom', 'MagpieData mean GSmagmom',\n",
       "       'MagpieData avg_dev GSmagmom', 'MagpieData mode GSmagmom',\n",
       "       'MagpieData minimum SpaceGroupNumber',\n",
       "       'MagpieData maximum SpaceGroupNumber',\n",
       "       'MagpieData range SpaceGroupNumber',\n",
       "       'MagpieData mean SpaceGroupNumber',\n",
       "       'MagpieData avg_dev SpaceGroupNumber',\n",
       "       'MagpieData mode SpaceGroupNumber', 'H', 'He', 'Li', 'Be', 'B',\n",
       "       'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl',\n",
       "       'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
       "       'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y',\n",
       "       'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',\n",
       "       'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm',\n",
       "       'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf',\n",
       "       'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi',\n",
       "       'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu',\n",
       "       'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr'], dtype=object)"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284,)"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = pd.DataFrame(final, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = generated.to_pickle(\"klgen_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(list(range(0,EPOCHS)),gloss)\n",
    "plt.plot(list(range(0,EPOCHS)),dloss)\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['generator loss','discriminator loss'])\n",
    "plt.savefig('Learning_curve GAN least squares')\n",
    "plt.show\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "df5fa5efdf1c60a896ccc8bc52bcd2fc69320846d08f7bc80e2522b0c75b6345"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
