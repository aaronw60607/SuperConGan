{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import data\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense,ZeroPadding2D, BatchNormalization, Activation, Layer, ReLU, LeakyReLU,Conv2D,AveragePooling2D,UpSampling2D,Reshape,Flatten\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('tcPred.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(60000).batch(1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21263, 147)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSHAPE = 147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(DSHAPE, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noise = tf.random.normal([1, DSHAPE])\n",
    "generated_image = generator(noise, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', use_bias=False, input_shape=(DSHAPE,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "   \n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints3'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = DSHAPE\n",
    "num_examples_to_generate = 50\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 147), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, gen_losses, disc_losses):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_losses = gen_losses.append(gen_loss.numpy())\n",
    "        disc_losses = disc_losses.append(disc_loss.numpy())\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs, gen_losses, disc_losses, gloss, dloss):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        train_step(image_batch, gen_losses,disc_losses)\n",
    "    print(\"gen_loss =\" + str(gen_losses[-1]))\n",
    "    print(\"disc_loss =\" + str(disc_losses[-1]))\n",
    "    gloss.append(gen_losses[-1])\n",
    "    dloss.append(disc_losses[-1])\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    x = generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  saved = generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "  return saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses = []\n",
    "disc_losses = []\n",
    "gloss = []\n",
    "dloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_loss =0.74790424\n",
      "disc_loss =1.3901504\n",
      "Time for epoch 1 is 1.3260841369628906 sec\n",
      "gen_loss =0.76873827\n",
      "disc_loss =1.3094921\n",
      "Time for epoch 2 is 1.2360258102416992 sec\n",
      "gen_loss =0.85500413\n",
      "disc_loss =1.1627905\n",
      "Time for epoch 3 is 1.233963966369629 sec\n",
      "gen_loss =0.97593963\n",
      "disc_loss =0.9474943\n",
      "Time for epoch 4 is 1.227733850479126 sec\n",
      "gen_loss =1.2233144\n",
      "disc_loss =0.7494606\n",
      "Time for epoch 5 is 1.216874122619629 sec\n",
      "gen_loss =1.5193243\n",
      "disc_loss =0.5610739\n",
      "Time for epoch 6 is 1.340061902999878 sec\n",
      "gen_loss =1.8429918\n",
      "disc_loss =0.4419149\n",
      "Time for epoch 7 is 1.2238600254058838 sec\n",
      "gen_loss =2.1377354\n",
      "disc_loss =0.4231651\n",
      "Time for epoch 8 is 1.5244152545928955 sec\n",
      "gen_loss =2.3765304\n",
      "disc_loss =0.31952667\n",
      "Time for epoch 9 is 1.3262419700622559 sec\n",
      "gen_loss =2.583664\n",
      "disc_loss =0.30382168\n",
      "Time for epoch 10 is 1.1973788738250732 sec\n",
      "gen_loss =2.7924395\n",
      "disc_loss =0.24832076\n",
      "Time for epoch 11 is 1.1975138187408447 sec\n",
      "gen_loss =2.941852\n",
      "disc_loss =0.22931208\n",
      "Time for epoch 12 is 1.2011771202087402 sec\n",
      "gen_loss =3.0583868\n",
      "disc_loss =0.20129979\n",
      "Time for epoch 13 is 1.2159740924835205 sec\n",
      "gen_loss =3.178741\n",
      "disc_loss =0.2052699\n",
      "Time for epoch 14 is 1.2265098094940186 sec\n",
      "gen_loss =3.27473\n",
      "disc_loss =0.27534354\n",
      "Time for epoch 15 is 1.2613000869750977 sec\n",
      "gen_loss =3.3981261\n",
      "disc_loss =0.17422807\n",
      "Time for epoch 16 is 1.2345850467681885 sec\n",
      "gen_loss =3.4178293\n",
      "disc_loss =0.25380883\n",
      "Time for epoch 17 is 1.2210369110107422 sec\n",
      "gen_loss =3.4736605\n",
      "disc_loss =0.1639123\n",
      "Time for epoch 18 is 1.2253341674804688 sec\n",
      "gen_loss =3.5219536\n",
      "disc_loss =0.2683792\n",
      "Time for epoch 19 is 1.222076177597046 sec\n",
      "gen_loss =3.5038395\n",
      "disc_loss =0.117693424\n",
      "Time for epoch 20 is 1.2278120517730713 sec\n",
      "gen_loss =3.6893158\n",
      "disc_loss =0.1494065\n",
      "Time for epoch 21 is 1.217343807220459 sec\n",
      "gen_loss =3.7744322\n",
      "disc_loss =0.11716209\n",
      "Time for epoch 22 is 1.2059710025787354 sec\n",
      "gen_loss =3.8897395\n",
      "disc_loss =0.15005817\n",
      "Time for epoch 23 is 1.216953992843628 sec\n",
      "gen_loss =4.071692\n",
      "disc_loss =0.097852774\n",
      "Time for epoch 24 is 1.2988109588623047 sec\n",
      "gen_loss =4.106941\n",
      "disc_loss =0.14590761\n",
      "Time for epoch 25 is 1.4251368045806885 sec\n",
      "gen_loss =4.1225243\n",
      "disc_loss =0.11565954\n",
      "Time for epoch 26 is 1.2978203296661377 sec\n",
      "gen_loss =4.46548\n",
      "disc_loss =0.08358093\n",
      "Time for epoch 27 is 1.238295078277588 sec\n",
      "gen_loss =4.5750604\n",
      "disc_loss =0.1507915\n",
      "Time for epoch 28 is 1.2272310256958008 sec\n",
      "gen_loss =4.7075696\n",
      "disc_loss =0.09110215\n",
      "Time for epoch 29 is 1.231468915939331 sec\n",
      "gen_loss =4.9253693\n",
      "disc_loss =0.11814158\n",
      "Time for epoch 30 is 1.2851498126983643 sec\n",
      "gen_loss =4.92719\n",
      "disc_loss =0.14863029\n",
      "Time for epoch 31 is 1.2940118312835693 sec\n",
      "gen_loss =5.155896\n",
      "disc_loss =0.12442939\n",
      "Time for epoch 32 is 1.2190020084381104 sec\n",
      "gen_loss =5.203965\n",
      "disc_loss =0.11410847\n",
      "Time for epoch 33 is 1.212745189666748 sec\n",
      "gen_loss =5.382759\n",
      "disc_loss =0.084800005\n",
      "Time for epoch 34 is 1.2326750755310059 sec\n",
      "gen_loss =5.4045644\n",
      "disc_loss =0.11468372\n",
      "Time for epoch 35 is 1.2994670867919922 sec\n",
      "gen_loss =5.5174313\n",
      "disc_loss =0.06640133\n",
      "Time for epoch 36 is 1.2412102222442627 sec\n",
      "gen_loss =5.4707565\n",
      "disc_loss =0.13366507\n",
      "Time for epoch 37 is 1.2204639911651611 sec\n",
      "gen_loss =5.559433\n",
      "disc_loss =0.06998529\n",
      "Time for epoch 38 is 1.2405807971954346 sec\n",
      "gen_loss =5.7264576\n",
      "disc_loss =0.11172873\n",
      "Time for epoch 39 is 1.223341941833496 sec\n",
      "gen_loss =5.6080265\n",
      "disc_loss =0.17718476\n",
      "Time for epoch 40 is 1.3901128768920898 sec\n",
      "gen_loss =5.690336\n",
      "disc_loss =0.07888411\n",
      "Time for epoch 41 is 1.2160429954528809 sec\n",
      "gen_loss =5.7443905\n",
      "disc_loss =0.082252026\n",
      "Time for epoch 42 is 1.211198091506958 sec\n",
      "gen_loss =5.7338996\n",
      "disc_loss =0.17998563\n",
      "Time for epoch 43 is 1.238189935684204 sec\n",
      "gen_loss =5.5376453\n",
      "disc_loss =0.1214219\n",
      "Time for epoch 44 is 1.3235182762145996 sec\n",
      "gen_loss =5.603488\n",
      "disc_loss =0.27853402\n",
      "Time for epoch 45 is 1.300832986831665 sec\n",
      "gen_loss =5.105597\n",
      "disc_loss =0.23266971\n",
      "Time for epoch 46 is 1.2331550121307373 sec\n",
      "gen_loss =4.9500866\n",
      "disc_loss =0.28367358\n",
      "Time for epoch 47 is 1.2404000759124756 sec\n",
      "gen_loss =5.061471\n",
      "disc_loss =0.22223625\n",
      "Time for epoch 48 is 1.2493419647216797 sec\n",
      "gen_loss =4.893219\n",
      "disc_loss =0.28174412\n",
      "Time for epoch 49 is 1.3613650798797607 sec\n",
      "gen_loss =4.726581\n",
      "disc_loss =0.39384687\n",
      "Time for epoch 50 is 1.253737211227417 sec\n"
     ]
    }
   ],
   "source": [
    "final = train(train_dataset,EPOCHS, gen_losses, disc_losses, gloss, dloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.eval of <tf.Tensor: shape=(50, 147), dtype=float32, numpy=\n",
       "array([[0.35870025, 0.13616791, 0.52748597, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51423615, 0.08325513, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19759572, 0.5894429 , 0.16179591, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.3432797 , 0.24079943, 0.3046231 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.6641716 , 0.39121783, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.31480506, 0.36993173, 0.09988488, ..., 0.        , 0.05688674,\n",
       "        0.        ]], dtype=float32)>>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = generator(tf.random.normal([1000, noise_dim]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 147), dtype=float32, numpy=\n",
       "array([[1.2872279 , 1.146098  , 1.3402513 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.1493005 , 0.8231228 , 0.8965121 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.06037267, 0.14508954, 0.8527348 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.1334085 , 1.412725  , 1.1848545 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.93419856, 1.3574717 , 0.5026217 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73384696, 0.3946967 , 0.78128475, ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.load('gitCol.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = pd.DataFrame(generated_images, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = generated.to_pickle(\"gen_data3.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(list(range(0,EPOCHS)),gloss)\n",
    "plt.plot(list(range(0,EPOCHS)),dloss)\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['generator loss','discriminator loss'])\n",
    "plt.savefig('Learning_curve gitdnn')\n",
    "plt.show\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "df5fa5efdf1c60a896ccc8bc52bcd2fc69320846d08f7bc80e2522b0c75b6345"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
